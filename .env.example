# =============================================================================
# Web Crawler with Crawl4AI - Environment Configuration
# =============================================================================
# Copy this file to .env and modify the values as needed
# cp .env.example .env

# =============================================================================
# BROWSER CONFIGURATION
# =============================================================================

# Run browser in headless mode (no GUI)
BROWSER_HEADLESS=true

# Browser viewport dimensions
BROWSER_VIEWPORT_WIDTH=1920
BROWSER_VIEWPORT_HEIGHT=1080

# Custom user agent (optional, uses default if not set)
# BROWSER_USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"

# Browser profile directory for persistent sessions
USER_DATA_DIR=~/.crawl4ai/browser_profile

# Enable verbose browser logging
BROWSER_VERBOSE=false

# Use persistent browser context for better performance
USE_PERSISTENT_CONTEXT=true

# =============================================================================
# CRAWLING BEHAVIOR
# =============================================================================

# Delay between requests in seconds (rate limiting)
CRAWL_DELAY=1.0

# Respect robots.txt files
RESPECT_ROBOTS_TXT=true

# Overall crawl timeout in seconds
CRAWL_TIMEOUT=60

# =============================================================================
# CONTENT EXTRACTION
# =============================================================================

# Extract links from crawled pages
EXTRACT_LINKS=true

# Extract images from crawled pages
EXTRACT_IMAGES=true

# Output format for content extraction
# Options: markdown, html, text
OUTPUT_FORMAT=markdown

# Wait for JavaScript to load and render
WAIT_FOR_JS=true

# JavaScript timeout in milliseconds
JS_TIMEOUT=8000

# Include JavaScript-rendered content
INCLUDE_JS_RENDERED=true


# =============================================================================
# DEEP CRAWLING DEFAULTS (for sub-URLs endpoint)
# =============================================================================

# Default crawl depth for deep crawling (1-5)
DEEP_CRAWL_DEPTH=5

# Default maximum pages to crawl
DEEP_CRAWL_MAX_PAGES=10

# Default crawl strategy (bfs, dfs, best_first)
DEEP_CRAWL_STRATEGY=best_first

# =============================================================================
# NOTES
# =============================================================================
# 
# 1. All boolean values can be: true, false, 1, 0, yes, no, on, off
# 2. Numeric values should be integers or floats as appropriate
# 3. String values should be quoted if they contain spaces
# 4. The .env file is automatically loaded by the application
# 5. Environment variables take precedence over .env file values
# 6. Default values are used if neither .env nor environment variables are set
#
# =============================================================================
